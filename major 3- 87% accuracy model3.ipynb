{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6383f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (0.2.54)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: mplfinance in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (0.12.10b0)\n",
      "Requirement already satisfied: numpy in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from requests>=2.31->yfinance) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from requests>=2.31->yfinance) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance mplfinance numpy pandas scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6eb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import mplfinance as mpf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a233f74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (0.2.54)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: mplfinance in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (0.12.10b0)\n",
      "Requirement already satisfied: numpy in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from requests>=2.31->yfinance) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\niraj\\anaconda3 4\\lib\\site-packages (from requests>=2.31->yfinance) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance mplfinance numpy pandas scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52403015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import yfinance as yf\\n\\n# List of tickers (AAPL + Indian stocks)\\ntickers = [\"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"HDFCBANK.NS\"]\\n\\n# Extended date range\\nstart_date = \"2023-01-01\"  # More historical data\\nend_date = \"2025-02-26\"  # Up to today\\n\\n# Dictionary to store data for each stock\\nstock_data = {}\\n\\n# Fetch stock data for each ticker\\nfor ticker in tickers:\\n    print(f\"ðŸ“¥ Fetching data for {ticker}...\")\\n    df = yf.download(ticker, start=start_date, end=end_date)\\n\\n    # Check if data is retrieved correctly\\n    if df.empty:\\n        print(f\"âš ï¸ No data found for {ticker}, skipping.\")\\n    else:\\n        df.reset_index(inplace=True)  # Ensure \\'Date\\' is a column\\n        stock_data[ticker] = df  # Store DataFrame\\n\\n# Print sample data for each stock\\nfor ticker, df in stock_data.items():\\n    print(f\"\\nðŸ“Š Sample Data for {ticker}:\")\\n    print(df.head())'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# List of tickers (AAPL + Indian stocks)\n",
    "tickers = [\"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"HDFCBANK.NS\"]\n",
    "\n",
    "# Extended date range\n",
    "start_date = \"2023-01-01\"  # More historical data\n",
    "end_date = \"2025-02-26\"  # Up to today\n",
    "\n",
    "# Dictionary to store data for each stock\n",
    "stock_data = {}\n",
    "\n",
    "# Fetch stock data for each ticker\n",
    "for ticker in tickers:\n",
    "    print(f\"ðŸ“¥ Fetching data for {ticker}...\")\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    # Check if data is retrieved correctly\n",
    "    if df.empty:\n",
    "        print(f\"âš ï¸ No data found for {ticker}, skipping.\")\n",
    "    else:\n",
    "        df.reset_index(inplace=True)  # Ensure 'Date' is a column\n",
    "        stock_data[ticker] = df  # Store DataFrame\n",
    "\n",
    "# Print sample data for each stock\n",
    "for ticker, df in stock_data.items():\n",
    "    print(f\"\\nðŸ“Š Sample Data for {ticker}:\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839cea1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"import yfinance as yf\\nimport pandas as pd\\n\\n# List of tickers (Indian stocks)\\ntickers = [\"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"HDFCBANK.NS\"]\\n\\n# Date range\\nstart_date = \"2022-01-01\"\\nend_date = \"2025-02-26\"\\n\\n# Dictionary to store stock data\\nstock_data = {}\\n\\nfor ticker in tickers:\\n    print(f\"ðŸ“¥ Fetching data for {ticker}...\")\\n    df = yf.download(ticker, start=start_date, end=end_date)\\n\\n    if df.empty:\\n        print(f\"âš ï¸ No data found for {ticker}, skipping.\")\\n    else:\\n        df.reset_index(inplace=True)  # Ensure \\'Date\\' is a column\\n        df.insert(1, \"Ticker\", ticker)  # Add a Ticker column\\n        \\n        # ðŸ› ï¸ Flatten MultiIndex columns (if any)\\n        if isinstance(df.columns, pd.MultiIndex):\\n            df.columns = [\"_\".join(col).strip() if isinstance(col, tuple) else col for col in df.columns]\\n\\n        # Standardize column names: remove spaces, convert to lowercase\\n        df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\\n\\n        # Rename columns to remove ticker-specific suffixes (e.g., close_aapl -> close)\\n        rename_dict = {col: col.split(\"_\")[0] if \"_\" in col else col for col in df.columns}\\n        df.rename(columns=rename_dict, inplace=True)\\n\\n        stock_data[ticker] = df  # Store cleaned DataFrame\\n\\n# Print sample data for each stock\\nfor ticker, df in stock_data.items():\\n    print(f\"\\nðŸ“Š Sample Data for {ticker}:\")\\n    print(df.head())'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of tickers (Indian stocks)\n",
    "tickers = [\"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"HDFCBANK.NS\"]\n",
    "\n",
    "# Date range\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2025-02-26\"-\n",
    "\n",
    "# Dictionary to store stock data\n",
    "stock_data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"ðŸ“¥ Fetching data for {ticker}...\")\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"âš ï¸ No data found for {ticker}, skipping.\")\n",
    "    else:\n",
    "        df.reset_index(inplace=True)  # Ensure 'Date' is a column\n",
    "        df.insert(1, \"Ticker\", ticker)  # Add a Ticker column\n",
    "        \n",
    "        # ðŸ› ï¸ Flatten MultiIndex columns (if any)\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = [\"_\".join(col).strip() if isinstance(col, tuple) else col for col in df.columns]\n",
    "\n",
    "        # Standardize column names: remove spaces, convert to lowercase\n",
    "        df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "        # Rename columns to remove ticker-specific suffixes (e.g., close_aapl -> close)\n",
    "        rename_dict = {col: col.split(\"_\")[0] if \"_\" in col else col for col in df.columns}\n",
    "        df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "        stock_data[ticker] = df  # Store cleaned DataFrame\n",
    "\n",
    "# Print sample data for each stock\n",
    "for ticker, df in stock_data.items():\n",
    "    print(f\"\\nðŸ“Š Sample Data for {ticker}:\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee860b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"import os\\nimport pandas as pd\\nimport mplfinance as mpf\\n\\n# Define directories for saving images\\noutput_dir = \"candlestick_images\"\\ncategories = [\"uptrend\", \"downtrend\", \"sideways\"]\\n\\n# Create directories if not exist\\nfor category in categories:\\n    os.makedirs(os.path.join(output_dir, category), exist_ok=True)\\n\\ndef generate_candlestick_images(df, ticker, save_path, window=20):\\n\\n    for i in range(len(df) - window):\\n        data_slice = df.iloc[i:i+window]\\n        \\n        # Identify trend direction\\n        start_price = data_slice.iloc[0][\\'close\\']\\n        end_price = data_slice.iloc[-1][\\'close\\']\\n        \\n        if end_price > start_price * 1.03:  # More than 3% increase\\n            category = \"uptrend\"\\n        elif end_price < start_price * 0.97:  # More than 3% decrease\\n            category = \"downtrend\"\\n        else:\\n            category = \"sideways\"\\n\\n        # Save path\\n        img_filename = f\"{ticker}_{i}.png\"\\n        img_filepath = os.path.join(save_path, category, img_filename)\\n        \\n        # Plot and save\\n        mpf.plot(data_slice.set_index(\"date\"), type=\"candle\", style=\"charles\",\\n                 savefig=img_filepath)\\n    \\n    print(f\"Saved {len(df) - window} images for {ticker}\")\\n\\n# Example usage: Generate images for each stock\\nfor ticker, df in stock_data.items():\\n    generate_candlestick_images(df, ticker, output_dir)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mplfinance as mpf\n",
    "\n",
    "# Define directories for saving images\n",
    "output_dir = \"candlestick_images\"\n",
    "categories = [\"uptrend\", \"downtrend\", \"sideways\"]\n",
    "\n",
    "# Create directories if not exist\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(output_dir, category), exist_ok=True)\n",
    "\n",
    "def generate_candlestick_images(df, ticker, save_path, window=20):\n",
    "\n",
    "    for i in range(len(df) - window):\n",
    "        data_slice = df.iloc[i:i+window]\n",
    "        \n",
    "        # Identify trend direction\n",
    "        start_price = data_slice.iloc[0]['close']\n",
    "        end_price = data_slice.iloc[-1]['close']\n",
    "        \n",
    "        if end_price > start_price * 1.03:  # More than 3% increase\n",
    "            category = \"uptrend\"\n",
    "        elif end_price < start_price * 0.97:  # More than 3% decrease\n",
    "            category = \"downtrend\"\n",
    "        else:\n",
    "            category = \"sideways\"\n",
    "\n",
    "        # Save path\n",
    "        img_filename = f\"{ticker}_{i}.png\"\n",
    "        img_filepath = os.path.join(save_path, category, img_filename)\n",
    "        \n",
    "        # Plot and save\n",
    "        mpf.plot(data_slice.set_index(\"date\"), type=\"candle\", style=\"charles\",\n",
    "                 savefig=img_filepath)\n",
    "    \n",
    "    print(f\"Saved {len(df) - window} images for {ticker}\")\n",
    "\n",
    "# Example usage: Generate images for each stock\n",
    "for ticker, df in stock_data.items():\n",
    "    generate_candlestick_images(df, ticker, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b64297b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"import os\\nimport numpy as np\\nimport tensorflow as tf\\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\\nfrom sklearn.model_selection import train_test_split\\nimport matplotlib.pyplot as plt\\n\\n# Define paths\\nbase_dir = \"candlestick_images\"  # Root folder containing trend category subfolders\\ncategories = [\"uptrend\", \"downtrend\", \"sideways\"]  # Trend labels\\n\\n# Image processing settings\\nimg_size = (128, 128)  # Resize all images to 128x128\\n\\n# Lists to store image data and labels\\nX, y = [], []\\n\\n# Load images from each category\\nfor label, category in enumerate(categories):\\n    category_path = os.path.join(base_dir, category)\\n    \\n    if not os.path.exists(category_path):\\n        print(f\"âš ï¸ Skipping missing folder: {category_path}\")\\n        continue\\n\\n    for image_name in os.listdir(category_path):\\n        img_path = os.path.join(category_path, image_name)\\n        try:\\n            # Load, resize, and convert image to array\\n            img = load_img(img_path, target_size=img_size)\\n            img_array = img_to_array(img) / 255.0  # Normalize pixels (0 to 1)\\n            \\n            # Append image and label\\n            X.append(img_array)\\n            y.append(label)  # 0 = uptrend, 1 = downtrend, 2 = sideways\\n        \\n        except Exception as e:\\n            print(f\"âŒ Error loading {img_path}: {e}\")\\n\\n# Convert lists to numpy arrays\\nX = np.array(X)\\ny = np.array(y)\\n\\n# Split into training (80%) and validation (20%) sets\\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\\n\\n# Display some images\\nplt.figure(figsize=(8, 6))\\nfor i in range(6):\\n    plt.subplot(2, 3, i+1)\\n    plt.imshow(X_train[i])\\n    plt.title(f\"Label: {categories[y_train[i]]}\")\\n    plt.axis(\"off\")\\n\\nplt.show()\\n\\nprint(\"âœ… Data Preprocessing Completed!\")\\nprint(f\"Total images: {len(X)}, Training: {len(X_train)}, Validation: {len(X_val)}\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "base_dir = \"candlestick_images\"  # Root folder containing trend category subfolders\n",
    "categories = [\"uptrend\", \"downtrend\", \"sideways\"]  # Trend labels\n",
    "\n",
    "# Image processing settings\n",
    "img_size = (128, 128)  # Resize all images to 128x128\n",
    "\n",
    "# Lists to store image data and labels\n",
    "X, y = [], []\n",
    "\n",
    "# Load images from each category\n",
    "for label, category in enumerate(categories):\n",
    "    category_path = os.path.join(base_dir, category)\n",
    "    \n",
    "    if not os.path.exists(category_path):\n",
    "        print(f\"âš ï¸ Skipping missing folder: {category_path}\")\n",
    "        continue\n",
    "\n",
    "    for image_name in os.listdir(category_path):\n",
    "        img_path = os.path.join(category_path, image_name)\n",
    "        try:\n",
    "            # Load, resize, and convert image to array\n",
    "            img = load_img(img_path, target_size=img_size)\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize pixels (0 to 1)\n",
    "            \n",
    "            # Append image and label\n",
    "            X.append(img_array)\n",
    "            y.append(label)  # 0 = uptrend, 1 = downtrend, 2 = sideways\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading {img_path}: {e}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split into training (80%) and validation (20%) sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display some images\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(f\"Label: {categories[y_train[i]]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Data Preprocessing Completed!\")\n",
    "print(f\"Total images: {len(X)}, Training: {len(X_train)}, Validation: {len(X_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "524e033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset successfully split into train and val folders!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "dataset_path = \"C:/Users/niraj/candlestick_images\"  \n",
    "train_path = os.path.join(dataset_path, \"train\")\n",
    "val_path = os.path.join(dataset_path, \"val\")\n",
    "\n",
    "# Create train/val directories if they donâ€™t exist\n",
    "for folder in [\"uptrend\", \"sideways\", \"downtrend\"]:\n",
    "    os.makedirs(os.path.join(train_path, folder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_path, folder), exist_ok=True)\n",
    "\n",
    "# Split images into train and val\n",
    "split_ratio = 0.8  # 80% train, 20% val\n",
    "for category in [\"uptrend\", \"sideways\", \"downtrend\"]:\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    image_files = os.listdir(category_path)\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    split_idx = int(len(image_files) * split_ratio)\n",
    "    train_files = image_files[:split_idx]\n",
    "    val_files = image_files[split_idx:]\n",
    "\n",
    "    for file in train_files:\n",
    "        shutil.move(os.path.join(category_path, file), os.path.join(train_path, category, file))\n",
    "\n",
    "    for file in val_files:\n",
    "        shutil.move(os.path.join(category_path, file), os.path.join(val_path, category, file))\n",
    "\n",
    "print(\"âœ… Dataset successfully split into train and val folders!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83c6f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum images in train: 759\n",
      "Minimum images in val: 232\n",
      "Copied 759 images to C:/Users/niraj/candlestick_balanced/train\\uptrend\n",
      "Copied 759 images to C:/Users/niraj/candlestick_balanced/train\\downtrend\n",
      "Copied 759 images to C:/Users/niraj/candlestick_balanced/train\\sideways\n",
      "Copied 232 images to C:/Users/niraj/candlestick_balanced/val\\uptrend\n",
      "Copied 232 images to C:/Users/niraj/candlestick_balanced/val\\downtrend\n",
      "Copied 232 images to C:/Users/niraj/candlestick_balanced/val\\sideways\n",
      "âœ… Balanced train & val datasets created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define base paths\n",
    "base_dir = \"C:/Users/niraj/candlestick_images\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "\n",
    "balanced_train_dir = \"C:/Users/niraj/candlestick_balanced/train\"\n",
    "balanced_val_dir = \"C:/Users/niraj/candlestick_balanced/val\"\n",
    "\n",
    "# Ensure balanced dataset directories exist\n",
    "for folder in [balanced_train_dir, balanced_val_dir]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Define class labels\n",
    "classes = [\"uptrend\", \"downtrend\", \"sideways\"]\n",
    "valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "# Function to get image count per class\n",
    "def get_image_count(base_path):\n",
    "    return {cls: len([img for img in os.listdir(os.path.join(base_path, cls)) if img.endswith(valid_extensions)]) for cls in classes}\n",
    "\n",
    "\n",
    "# Find the minimum number of images across all classes in train and val\n",
    "train_counts = get_image_count(train_dir)\n",
    "val_counts = get_image_count(val_dir)\n",
    "\n",
    "min_train = min(train_counts.values())\n",
    "min_val = min(val_counts.values())\n",
    "\n",
    "print(f\"Minimum images in train: {min_train}\")\n",
    "print(f\"Minimum images in val: {min_val}\")\n",
    "\n",
    "# Undersampling: Keep only `min_train` and `min_val` images per class\n",
    "for mode, source_dir, dest_dir, min_count in [(\"train\", train_dir, balanced_train_dir, min_train),\n",
    "                                              (\"val\", val_dir, balanced_val_dir, min_val)]:\n",
    "    for cls in classes:\n",
    "        cls_source_path = os.path.join(source_dir, cls)\n",
    "        cls_dest_path = os.path.join(dest_dir, cls)\n",
    "\n",
    "        os.makedirs(cls_dest_path, exist_ok=True)\n",
    "\n",
    "        img_list = [img for img in os.listdir(cls_source_path) if img.endswith(valid_extensions)]\n",
    "        random.shuffle(img_list)\n",
    "\n",
    "        # Select `min_count` images\n",
    "        selected_images = img_list[:min_count]\n",
    "\n",
    "        # Copy images to respective directories\n",
    "        for img in selected_images:\n",
    "            shutil.copy(os.path.join(cls_source_path, img), os.path.join(cls_dest_path, img))\n",
    "\n",
    "        print(f\"Copied {len(selected_images)} images to {cls_dest_path}\")\n",
    "\n",
    "print(\"âœ… Balanced train & val datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79616abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"from tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import (\\n    Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, \\n    BatchNormalization, LeakyReLU\\n)\\nfrom tensorflow.keras.regularizers import l2\\nfrom tensorflow.keras.optimizers import Adam\\n\\n# Define Optimized CNN Model\\nmodel = Sequential([\\n    # Input Layer\\n    Input(shape=(128, 128, 3)),  \\n\\n    # Convolutional Block 1\\n    Conv2D(32, (3, 3), padding=\\'same\\', kernel_regularizer=l2(0.001)),\\n    LeakyReLU(negative_slope=0.1),  # Fixed warning\\n    BatchNormalization(),\\n    MaxPooling2D(pool_size=(2, 2)),\\n    Dropout(0.2),\\n\\n    # Convolutional Block 2\\n    Conv2D(64, (3, 3), padding=\\'same\\', kernel_regularizer=l2(0.001)),\\n    LeakyReLU(negative_slope=0.1),\\n    BatchNormalization(),\\n    MaxPooling2D(pool_size=(2, 2)),\\n    Dropout(0.3),\\n\\n    # Convolutional Block 3\\n    Conv2D(128, (3, 3), padding=\\'same\\', kernel_regularizer=l2(0.001)),\\n    LeakyReLU(negative_slope=0.1),\\n    BatchNormalization(),\\n    MaxPooling2D(pool_size=(2, 2)),\\n    Dropout(0.3),\\n\\n    # Convolutional Block 4\\n    Conv2D(256, (3, 3), padding=\\'same\\', kernel_regularizer=l2(0.001)),\\n    LeakyReLU(negative_slope=0.1),\\n    BatchNormalization(),\\n    MaxPooling2D(pool_size=(2, 2)),\\n    Dropout(0.4),\\n\\n    # Global Average Pooling instead of Flatten\\n    GlobalAveragePooling2D(),  \\n\\n    # Fully Connected Layers\\n    Dense(256, kernel_regularizer=l2(0.0001)),  # Reduced from 512 â†’ 256\\n    LeakyReLU(negative_slope=0.1),\\n    BatchNormalization(),\\n    Dropout(0.5),\\n\\n    Dense(128, kernel_regularizer=l2(0.0001)),  # Reduced from 256 â†’ 128\\n    LeakyReLU(negative_slope=0.1),\\n    BatchNormalization(),\\n    Dropout(0.5),\\n\\n    # Output Layer\\n    Dense(3, activation=\\'softmax\\')\\n])\\n\\n# Compile with Adaptive Learning Rate\\noptimizer = Adam(learning_rate=0.0001)\\nmodel.compile(optimizer=optimizer, loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n# Model Summary\\nmodel.summary()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, \n",
    "    BatchNormalization, LeakyReLU\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define Optimized CNN Model\n",
    "model = Sequential([\n",
    "    # Input Layer\n",
    "    Input(shape=(128, 128, 3)),  \n",
    "\n",
    "    # Convolutional Block 1\n",
    "    Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(negative_slope=0.1),  # Fixed warning\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Convolutional Block 4\n",
    "    Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Global Average Pooling instead of Flatten\n",
    "    GlobalAveragePooling2D(),  \n",
    "\n",
    "    # Fully Connected Layers\n",
    "    Dense(256, kernel_regularizer=l2(0.0001)),  # Reduced from 512 â†’ 256\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(128, kernel_regularizer=l2(0.0001)),  # Reduced from 256 â†’ 128\n",
    "    LeakyReLU(negative_slope=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Output Layer\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile with Adaptive Learning Rate\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad7e045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2612 images belonging to 3 classes.\n",
      "Found 787 images belonging to 3 classes.\n",
      "Found 48 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niraj\\anaconda3 4\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 1s/step - accuracy: 0.3456 - loss: 1.1234 - val_accuracy: 0.3621 - val_loss: 1.0991 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.3304 - loss: 1.1085 - val_accuracy: 0.3431 - val_loss: 1.0970 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.3468 - loss: 1.0972 - val_accuracy: 0.3621 - val_loss: 1.0964 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.3491 - loss: 1.0988 - val_accuracy: 0.3621 - val_loss: 1.0951 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.3675 - loss: 1.0934 - val_accuracy: 0.3621 - val_loss: 1.0950 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.3630 - loss: 1.0939 - val_accuracy: 0.3621 - val_loss: 1.0950 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.3564 - loss: 1.0963 - val_accuracy: 0.3621 - val_loss: 1.0950 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881ms/step - accuracy: 0.3587 - loss: 1.0967\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.3588 - loss: 1.0967 - val_accuracy: 0.3621 - val_loss: 1.0950 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.3693 - loss: 1.0932 - val_accuracy: 0.3621 - val_loss: 1.0950 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 1s/step - accuracy: 0.3669 - loss: 1.0954 - val_accuracy: 0.3621 - val_loss: 1.0950 - learning_rate: 5.0000e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 1/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - accuracy: 0.4115 - loss: 1.1214 - val_accuracy: 0.3621 - val_loss: 1.0952 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5462 - loss: 0.9514 - val_accuracy: 0.3609 - val_loss: 1.0984 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.6312 - loss: 0.8124 - val_accuracy: 0.4549 - val_loss: 1.0973 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.6749 - loss: 0.7086 - val_accuracy: 0.6633 - val_loss: 0.7186 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.6721 - loss: 0.7137 - val_accuracy: 0.8335 - val_loss: 0.4573 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - accuracy: 0.7161 - loss: 0.6263 - val_accuracy: 0.8247 - val_loss: 0.4130 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.7140 - loss: 0.6193 - val_accuracy: 0.8539 - val_loss: 0.3977 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step - accuracy: 0.7440 - loss: 0.5846 - val_accuracy: 0.8640 - val_loss: 0.3329 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.7339 - loss: 0.6102 - val_accuracy: 0.8767 - val_loss: 0.3311 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.7828 - loss: 0.5118 - val_accuracy: 0.8628 - val_loss: 0.3231 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.7868 - loss: 0.4938 - val_accuracy: 0.8844 - val_loss: 0.2932 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.7852 - loss: 0.5256 - val_accuracy: 0.8717 - val_loss: 0.3058 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.7849 - loss: 0.5123 - val_accuracy: 0.8717 - val_loss: 0.2967 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7940 - loss: 0.4858\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 2s/step - accuracy: 0.7940 - loss: 0.4857 - val_accuracy: 0.8717 - val_loss: 0.3172 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 2s/step - accuracy: 0.8221 - loss: 0.4330 - val_accuracy: 0.8996 - val_loss: 0.2472 - learning_rate: 5.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - accuracy: 0.8064 - loss: 0.4402 - val_accuracy: 0.8996 - val_loss: 0.2371 - learning_rate: 5.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.7950 - loss: 0.4629 - val_accuracy: 0.9060 - val_loss: 0.2357 - learning_rate: 5.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 2s/step - accuracy: 0.8144 - loss: 0.4475 - val_accuracy: 0.8983 - val_loss: 0.2480 - learning_rate: 5.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.8179 - loss: 0.4264 - val_accuracy: 0.9098 - val_loss: 0.2231 - learning_rate: 5.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - accuracy: 0.8264 - loss: 0.4064 - val_accuracy: 0.9060 - val_loss: 0.2224 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374ms/step - accuracy: 0.8646 - loss: 0.3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Data paths\n",
    "train_dir = \"C:/Users/niraj/candlestick_balanced/train\"\n",
    "val_dir = \"C:/Users/niraj/candlestick_balanced/val\"\n",
    "test_dir = \"C:/Users/niraj/candlestick_balanced/test\"\n",
    "\n",
    "\n",
    "# Image size and batch size\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "# Load EfficientNetB0 with pre-trained weights\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base model layers initially\n",
    "\n",
    "# Build custom model on top\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "out = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[lr_reduction, early_stopping]\n",
    ")\n",
    "\n",
    "# Fine-tune: Unfreeze some layers and train again\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:  # Freeze first 100 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[lr_reduction, early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save model\n",
    "model.save(\"candlestick_model1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0c32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"candlestick_model3.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
